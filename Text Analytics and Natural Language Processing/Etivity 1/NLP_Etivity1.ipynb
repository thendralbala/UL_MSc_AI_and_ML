{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOolnw/C183FnS2wLIglzxl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thendralbala/UL_MSc_AI_and_ML/blob/main/NLP_Etivity1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Dependencies"
      ],
      "metadata": {
        "id": "yqGzLVjxx_1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install html2text\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "from html2text import html2text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72gZDdTJvMcB",
        "outputId": "f7a9f197-33d8-45e8-c0e5-43122e0fe3a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting html2text\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: html2text\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=d704b8cee1689561936462ec4e640e462aa577afbd5a4dd2024b174f796b0d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\n",
            "Successfully built html2text\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2024.2.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1.1: Validate and Process Eircode"
      ],
      "metadata": {
        "id": "0ZbqoofexgaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia4EArF_uzSZ",
        "outputId": "9d70434f-8425-4414-9818-2db2c38c2be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid Eircode: 111-T9PX. Unknown Routing Key.\n",
            "Valid Eircode: V94-T9PX. District: LIMERICK\n",
            "Valid Eircode: V94 T9PX. District: LIMERICK\n",
            "Valid Eircode: V94T9PX. District: LIMERICK\n",
            "Valid Eircode:  V94-T9PX. District: LIMERICK\n",
            "Valid Eircode: V94-T9PX . District: LIMERICK\n",
            "Valid Eircode: v94 T9PX. District: LIMERICK\n",
            "Invalid Eircode: V94T9PXV. Does not match pattern.\n"
          ]
        }
      ],
      "source": [
        "# Download CSV for Routing Keys\n",
        "csv_url = \"https://gist.githubusercontent.com/ajoorabchi/eac194a79dd26de8864f9206b7842ff1/raw/8ea1d8d5f74b5b2724e378b43d4df6094990c7db/Eircode%2520Routing%2520Key%2520Boundaries.csv\"\n",
        "response = requests.get(csv_url)\n",
        "routing_keys = {}\n",
        "\n",
        "if response.status_code == 200:\n",
        "    reader = csv.reader(response.text.splitlines())\n",
        "    for row in reader:\n",
        "        routing_keys[row[0]] = row[1]\n",
        "\n",
        "# Eircode Validator\n",
        "def eircodeValidator(eircode):\n",
        "    pattern = r\"^(\\w{3})[-\\s]?(\\w{4})$\"\n",
        "    match = re.match(pattern, eircode.strip().upper())\n",
        "    if match:\n",
        "        routing_key = match.group(1)\n",
        "        if routing_key in routing_keys:\n",
        "            print(f\"Valid Eircode: {eircode}. District: {routing_keys[routing_key]}\")\n",
        "        else:\n",
        "            print(f\"Invalid Eircode: {eircode}. Unknown Routing Key.\")\n",
        "    else:\n",
        "        print(f\"Invalid Eircode: {eircode}. Does not match pattern.\")\n",
        "\n",
        "# Test Cases\n",
        "eircodeValidator(\"111-T9PX\")\n",
        "eircodeValidator(\"V94-T9PX\")\n",
        "eircodeValidator(\"V94 T9PX\")\n",
        "eircodeValidator(\"V94T9PX\")\n",
        "eircodeValidator(\" V94-T9PX\")\n",
        "eircodeValidator(\"V94-T9PX \")\n",
        "eircodeValidator(\"v94 T9PX\")\n",
        "eircodeValidator(\"V94T9PXV\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1.2: Extract Contacts"
      ],
      "metadata": {
        "id": "DWn2BqI5xlI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download UL contact information\n",
        "url = \"https://www.ul.ie/contact-information\"\n",
        "html_response = requests.get(url)\n",
        "contact_text = html2text(html_response.text)\n",
        "\n",
        "def contactsExtractor(text):\n",
        "    phone_pattern = r\"\\b\\d{5,15}\\b\"\n",
        "    email_pattern = r\"[\\w.-]+@[\\w.-]+\\.[a-z]{2,}\"\n",
        "    website_pattern = r\"https?://[\\w.-]+|www\\.[\\w.-]+\"\n",
        "\n",
        "    phones = re.findall(phone_pattern, text)\n",
        "    emails = re.findall(email_pattern, text)\n",
        "    websites = re.findall(website_pattern, text)\n",
        "\n",
        "    print(f\"{len(phones)} Phone Numbers found: {phones}\")\n",
        "    print(f\"{len(emails)} Emails found: {emails}\")\n",
        "    print(f\"{len(websites)} Websites found: {websites}\")\n",
        "\n",
        "contactsExtractor(contact_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_XZ3PrNvG7u",
        "outputId": "eaa293fc-b94d-403d-e51d-fb39588d9942"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 Phone Numbers found: ['139046', '143553', '202700', '0035361202700', '213333', '061213333', '85607', '234377', '203154', '0035361203154', '213062', '202286', '0035361202286', '213081', '234392', '202688', '0035361202688', '202602', '202116', '0035361202116', '336559', '202700', '202700', '20009274']\n",
            "12 Emails found: ['reception@ul.ie', 'reception@ul.ie', 'international@ul.ie', 'international@ul.ie', 'DeanFAHSS@ul.ie', 'DeanFAHSS@ul.ie', 'ehs@ul.ie', 'ehs@ul.ie', 'scieng@ul.ie', 'scieng@ul.ie', 'kbsdean@ul.ie', 'kbsdean@ul.ie']\n",
            "41 Websites found: ['https://www.facebook.com', 'https://twitter.com', 'https://www.instagram.com', 'https://www.linkedin.com', 'https://www.youtube.com', 'https://www.tiktok.com', 'https://www.ul.ie', 'https://ul.workvivo.com', 'https://www.ul.ie', 'https://www.youvisit.com', 'https://www.ul.ie', 'https://www.ul.ie', 'https://www.ul.ie', 'https://pure.ul.ie', 'https://www.ul.ie', 'https://ulfoundation.com', 'https://campuslife.ul.ie', 'https://visitorservices.ul.ie', 'https://www.ul.ie', 'https://ulvisitorcentre.ie', 'http://www.ulsport.ie', 'https://www.ul.ie', 'https://www.ul.ie', 'https://www.ul.ie', 'www.ul.ie', 'https://www.ul.ie', 'www.ul.ie', 'www.ul.ie', 'http://tel', 'www.ul.ie', 'www.ul.ie', 'https://www.outlook.com', 'https://portal.office.com', 'https://www.ul.ie', 'https://eufunds.ie', 'https://www.facebook.com', 'https://twitter.com', 'https://www.instagram.com', 'https://www.linkedin.com', 'https://www.youtube.com', 'https://www.tiktok.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.1: Process Shakespeare Corpus"
      ],
      "metadata": {
        "id": "4zo0sSqOxp-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_url = \"http://www.gutenberg.org/files/100/100-0.txt\"\n",
        "shakespeare_response = requests.get(shakespeare_url)\n",
        "if shakespeare_response.status_code == 200:\n",
        "    shakespeare_content = shakespeare_response.text.splitlines()\n",
        "    print(\"\\n\".join(shakespeare_content[:50]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkO3LsE7vR44",
        "outputId": "58a0e697-7849-4fb6-c2bb-30e88857d1c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** START OF THE PROJECT GUTENBERG EBOOK 100 ***\n",
            "The Complete Works of William Shakespeare\n",
            "\n",
            "by William Shakespeare\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                    Contents\n",
            "\n",
            "    THE SONNETS\n",
            "    ALL’S WELL THAT ENDS WELL\n",
            "    THE TRAGEDY OF ANTONY AND CLEOPATRA\n",
            "    AS YOU LIKE IT\n",
            "    THE COMEDY OF ERRORS\n",
            "    THE TRAGEDY OF CORIOLANUS\n",
            "    CYMBELINE\n",
            "    THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\n",
            "    THE FIRST PART OF KING HENRY THE FOURTH\n",
            "    THE SECOND PART OF KING HENRY THE FOURTH\n",
            "    THE LIFE OF KING HENRY THE FIFTH\n",
            "    THE FIRST PART OF HENRY THE SIXTH\n",
            "    THE SECOND PART OF KING HENRY THE SIXTH\n",
            "    THE THIRD PART OF KING HENRY THE SIXTH\n",
            "    KING HENRY THE EIGHTH\n",
            "    THE LIFE AND DEATH OF KING JOHN\n",
            "    THE TRAGEDY OF JULIUS CAESAR\n",
            "    THE TRAGEDY OF KING LEAR\n",
            "    LOVE’S LABOUR’S LOST\n",
            "    THE TRAGEDY OF MACBETH\n",
            "    MEASURE FOR MEASURE\n",
            "    THE MERCHANT OF VENICE\n",
            "    THE MERRY WIVES OF WINDSOR\n",
            "    A MIDSUMMER NIGHT’S DREAM\n",
            "    MUCH ADO ABOUT NOTHING\n",
            "    THE TRAGEDY OF OTHELLO, THE MOOR OF VENICE\n",
            "    PERICLES, PRINCE OF TYRE\n",
            "    KING RICHARD THE SECOND\n",
            "    KING RICHARD THE THIRD\n",
            "    THE TRAGEDY OF ROMEO AND JULIET\n",
            "    THE TAMING OF THE SHREW\n",
            "    THE TEMPEST\n",
            "    THE LIFE OF TIMON OF ATHENS\n",
            "    THE TRAGEDY OF TITUS ANDRONICUS\n",
            "    TROILUS AND CRESSIDA\n",
            "    TWELFTH NIGHT; OR, WHAT YOU WILL\n",
            "    THE TWO GENTLEMEN OF VERONA\n",
            "    THE TWO NOBLE KINSMEN\n",
            "    THE WINTER’S TALE\n",
            "    A LOVER’S COMPLAINT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.2: Tokenize Shakespeare Corpus"
      ],
      "metadata": {
        "id": "Ajgb0fpFxs2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(shakespeare_content)\n",
        "tokens = tokenizer.word_counts\n",
        "\n",
        "total_tokens = sum(tokens.values())\n",
        "total_types = len(tokens)\n",
        "top_10 = sorted(tokens.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "print(f\"Total Tokens: {total_tokens}\")\n",
        "print(f\"Total Types: {total_types}\")\n",
        "for rank, (word, freq) in enumerate(top_10, 1):\n",
        "    print(f'\"{word}\" is ranked #{rank}, with a frequency of {freq}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmLheaJnvWYt",
        "outputId": "ac4e1e50-b527-4988-907f-c31711946f55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 969435\n",
            "Total Types: 29851\n",
            "\"the\" is ranked #1, with a frequency of 30309\n",
            "\"and\" is ranked #2, with a frequency of 28430\n",
            "\"i\" is ranked #3, with a frequency of 21694\n",
            "\"to\" is ranked #4, with a frequency of 20944\n",
            "\"of\" is ranked #5, with a frequency of 18742\n",
            "\"a\" is ranked #6, with a frequency of 16371\n",
            "\"you\" is ranked #7, with a frequency of 14332\n",
            "\"my\" is ranked #8, with a frequency of 13162\n",
            "\"in\" is ranked #9, with a frequency of 12412\n",
            "\"that\" is ranked #10, with a frequency of 11779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.3: Stem and Lemmatize Types"
      ],
      "metadata": {
        "id": "0EMxubSDxxUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmed_types = set(ps.stem(word) for word in tokens.keys())\n",
        "lemmatized_types = set(lemmatizer.lemmatize(word) for word in tokens.keys())\n",
        "\n",
        "print(f\"Total Types: {total_types}\")\n",
        "print(f\"Total Stems: {len(stemmed_types)}\")\n",
        "print(f\"Total Lemmas: {len(lemmatized_types)}\")\n",
        "print(f\"{total_types} > {len(lemmatized_types)} > {len(stemmed_types)} is valid: {total_types > len(lemmatized_types) > len(stemmed_types)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SGz9noNvc8w",
        "outputId": "c4747f08-0623-4415-a97d-c89c3e16e813"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Types: 29851\n",
            "Total Stems: 20744\n",
            "Total Lemmas: 26575\n",
            "29851 > 26575 > 20744 is valid: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.4: Segment Sentences"
      ],
      "metadata": {
        "id": "rjVlF823x14P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "last_100_lines = \"\\n\".join(shakespeare_content[-100:])\n",
        "doc = nlp(last_100_lines)\n",
        "sentences = list(doc.sents)\n",
        "\n",
        "print(f\"Total Sentences: {len(sentences)}\")\n",
        "for sentence in sentences:\n",
        "    print(sentence.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht3epClBvjUq",
        "outputId": "00b9676f-539b-4077-b86f-9589d6da49cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences: 27\n",
            "But by a kiss thought to persuade him there;\n",
            "  And nuzzling in his flank, the loving swine\n",
            "  Sheath’d unaware the tusk in his soft groin.      \n",
            "1116\n",
            "\n",
            "“Had I been tooth’d like him\n",
            ", I must confess,\n",
            "With kissing him\n",
            "I should have kill’d him first;\n",
            "\n",
            "But he is dead, and never did he bless\n",
            "My youth with his; the more am I accurst.”          \n",
            "1120\n",
            "  With this she falleth in the place she stood,\n",
            "  And stains her face with his congealed blood.\n",
            "\n",
            "\n",
            "She looks upon his lips, and they are pale;\n",
            "She takes him by the hand, and that is cold,        1124\n",
            "She whispers in his ears a heavy tale,\n",
            "\n",
            "As if they heard the woeful words she told;\n",
            "She lifts the coffer-lids that close his eyes,\n",
            "Where lo, two lamps burnt out in darkness lies.\n",
            "\n",
            "\n",
            "Two glasses where herself herself beheld            1129\n",
            "A thousand times, and now no more reflect;\n",
            "Their virtue lost, wherein they late excell’d,\n",
            "And every beauty robb’d of his effect.              \n",
            "1132\n",
            "  “Wonder of time,” quoth she, “this is my spite,\n",
            "  That thou being dead, the day should yet be light.\n",
            "\n",
            "\n",
            "“Since thou art dead, lo here I prophesy,\n",
            "Sorrow on love hereafter shall attend:              1136\n",
            "It shall be waited on with jealousy,\n",
            "Find sweet beginning, but unsavoury end;\n",
            "  Ne’er settled equally, but high or low,\n",
            "  That all love’s pleasure shall not match his woe.\n",
            "\n",
            "\n",
            "“It shall be fickle, false and full of fraud,       1141\n",
            "Bud, and be blasted in a breathing while;\n",
            "The bottom poison, and the top o’erstraw’d\n",
            "With sweets that shall the truest sight beguile.    \n",
            "1144\n",
            "  The strongest body shall it make most weak,\n",
            "  Strike the wise dumb, and teach the fool to speak.\n",
            "\n",
            "\n",
            "“It shall be sparing, and too full of riot,\n",
            "Teaching decrepit age to tread the measures;        1148\n",
            "\n",
            "The staring ruffian shall it keep in quiet,\n",
            "Pluck down the rich, enrich the poor with treasures;\n",
            "  It shall be raging mad, and silly mild,\n",
            "  Make the young old, the old become a child.       \n",
            "1152\n",
            "\n",
            "“It shall suspect where is no cause of fear,\n",
            "It shall not fear where it should most mistrust;\n",
            "It shall be merciful, and too severe,\n",
            "And most deceiving when it seems most just;         1156\n",
            "  Perverse it shall be, where it shows most toward,\n",
            "  Put fear to valour, courage to the coward.\n",
            "\n",
            "\n",
            "“It shall be cause of war and dire events,\n",
            "And set dissension ’twixt the son and sire;         1160\n",
            "Subject and servile to all discontents,\n",
            "As dry combustious matter is to fire,\n",
            "  Sith in his prime death doth my love destroy,\n",
            "  They that love best their love shall not enjoy.”  \n",
            "1164\n",
            "\n",
            "\n",
            "By this the boy that by her side lay kill’d\n",
            "Was melted like a vapour from her sight,\n",
            "And in his blood that on the ground lay spill’d,\n",
            "A purple flower sprung up, chequer’d with white,    1168\n",
            "  \n",
            "Resembling well his pale cheeks, and the blood\n",
            "  Which in round drops upon their whiteness stood.\n",
            "\n",
            "\n",
            "She bows her head, the new-sprung flower to smell,\n",
            "Comparing it to her Adonis’ breath;                 1172\n",
            "And says within her bosom it shall dwell,\n",
            "Since he himself is reft from her by death;\n",
            "  She drops the stalk, and in the breach appears\n",
            "  Green-dropping sap, which she compares to tears.\n",
            "\n",
            "\n",
            "“Poor flower,” quoth she, “this was thy father’s guise,\n",
            "Sweet issue of a more sweet-smelling sire,\n",
            "For every little grief to wet his eyes,\n",
            "To grow unto himself was his desire,                1180\n",
            "  And so ’tis thine; but know, it is as good\n",
            "  To wither in my breast as in his blood.\n",
            "\n",
            "\n",
            "“Here was thy father’s bed, here in my breast;\n",
            "\n",
            "Thou art the next of blood, and ’tis thy right:     1184\n",
            "Lo in this hollow cradle take thy rest,\n",
            "My throbbing heart shall rock thee day and night:\n",
            "  There shall not be one minute in an hour\n",
            "  \n",
            "Wherein I will not kiss my sweet love’s flower.”\n",
            "\n",
            "\n",
            "Thus weary of the world, away she hies,             1189\n",
            "And yokes her silver doves; by whose swift aid\n",
            "Their mistress mounted through the empty skies,\n",
            "In her light chariot quickly is convey’d;           1192\n",
            "  Holding their course to Paphos, where their queen\n",
            "  Means to immure herself and not be seen.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  \n",
            "FINIS\n",
            "*** END OF THE PROJECT GUTENBERG EBOOK 100 ***\n"
          ]
        }
      ]
    }
  ]
}
